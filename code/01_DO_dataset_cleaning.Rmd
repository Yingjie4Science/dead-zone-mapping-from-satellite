---
output: html_document
editor_options: 
  chunk_output_type: console
---


# Dirs and Packages
```{r}
# To clear your environment 
remove(list = ls())


library(readxl)
library(XLConnect)
library(xlsx)
library(tidyverse)
library(dplyr)
library(proj4)
library(stringr)
library(scales)

library(sf)
library(maps)
library(mapdata)

library(RColorBrewer)
library(viridis)
# devtools::install_github("jaredhuling/jcolors")
library(jcolors)



### Set work dir ----------------------------------------------------------
path <- rstudioapi::getSourceEditorContext()$path
dir  <- dirname(rstudioapi::getSourceEditorContext()$path); dir
dirname(dir)        ## go to parent dir
setwd(dirname(dir)) ## set this parent dir as root dir
getwd()

### the data fir 
dir.path <- './data/DO/DO_GOM/DO_Integrated_Matli_NCSU'
setwd(dir.path)
getwd()

dir.fig    <- './figures/'
dir.output <- './data_cleaned/'


today <- format(Sys.time(), "%Y%m%d"); print(today)


## keep more decimals 
options(digits = 15)
options(pillar.sigfig = 15)
```


*Data source*: 
  Rohith Matli, Center for Geospatial Analytics, North Carolina State University; vmatli@ncsu.edu
  
*Reference*:  
  Matli, Venkata Rohith Reddy, Shiqi Fang, Joseph Guinness, Nancy N Rabalais, J. Kevin Craig, and Daniel R. Obenour. “A Space-Time Geostatistical Assessment of Hypoxia in the Northern Gulf of Mexico.” Environmental Science & Technology, September 28, 2018. https://doi.org/10.1021/acs.est.8b03474.
  Matli, Venkata Rohith Reddy, Arnaud Laurent, Katja Fennel, Kevin Craig, Jacob Krause, and Daniel R. Obenour. “Fusion-Based Hypoxia Estimates: Combining Geostatistical and Mechanistic Models of Dissolved Oxygen Variability.” Environmental Science & Technology, September 3, 2020. https://doi.org/10.1021/acs.est.0c03655


# Data read in

**SBToML** - Observations from *Seabird* Instrument - Rosette mounted sensor. Don’t Usually go all the way to the bottom of the ocean but have complete profile information

**HLToML** - Observations from *Handhold DO probes* - Mostly used by *LUMCON*. Usually go all the way to the bottom of the ocean. But don’t have complete water column profiles like rosette mounted sensors.

**StatoML** - Summary of all Locations and dates of observations with the Keys (YEID) linking to the observations in SBToML and HLToMl data files.
	- E&N in UTM Zone 15N (km) . Note if transformations are used Zone 15N is usually read in m, so apply a correction factor
	- Depth in m. Obtained from NOAA raster. Refer Obenour' 2015 or Matli' 2018
	- ShelfW: Whether the cruise is shelfwide or focuses of certain sections of the shelf
	- Source: Organization collecting data
	- Corr: Addition correction factor applied to account for bias in sampling
**Note**
  - UMCES observations were not binned properly when exported from CTD software, resulting in fine scale profile information. 
	- Some observations have observations from both lowering and raising of the rosette
	- Some observations have readings from both Rosette and handhold probes. Mostly in the case of data collected by LUMCON (Nancy's Program)
	- LDWF have limited spatial range. 


## Read data raw
```{r }
### Read in data ------------------------------------------------------------
getwd()
list.files(path = './data_raw', pattern = '.xlsx$', full.names = T)

df1.xlsx <- list.files(path = './data_raw', pattern = '^Summary.xlsx', full.names = T); df1.xlsx
df2.xlsx <- list.files(path = './data_raw', pattern = '^RawData.xlsx', full.names = T); df2.xlsx

df11 <- read_excel(path = df1.xlsx, sheet = 1, col_names = T) # Summary
df21 <- read_excel(path = df2.xlsx, sheet = 1, col_names = T) # SBToML
df22 <- read_excel(path = df2.xlsx, sheet = 2, col_names = T) # HLToML
df23 <- read_excel(path = df2.xlsx, sheet = 3, col_names = T) # StaToML

# df <- read.xlsx(file = df.xlsx, sheetName = "StaToML", as.data.frame = T)
# library("openxlsx")
# df <- read.xlsx(xlsxFile = df.xlsx, sheet = 'StaToML', colNames = TRUE)


## the summary data file
dfsummary <- df11; names(dfsummary)
dfsummary %>% ggplot() + geom_histogram(aes(x = MaxSamplingDepth)) + theme_bw() ## 0 - 100 m 
dfsummary %>% ggplot() + geom_histogram(aes(x = BWDO)) + theme_bw()             ## 0 - 15 m
dfsummary %>% group_by(Source) %>% tally() %>%                                  ## 8 Sources? 
  ggplot() + geom_col(aes(x = Source, y = n)) + theme_bw()
dfsummary %>% dplyr::filter(is.na(Source))



## observation data 1
sb <- df21 %>% as.data.frame() ## Observations from Seabird Instrument. Don’t Usually go all the way to the bottom of the ocean but have complete profile information

## observation data 2
hh <- df22 %>% as.data.frame() ## Observations from Handheld DO probes - Mostly used by LUMCON. Usually go all the way to the bottom of the ocean. But don’t have complete water column profiles like rosette mounted sensors

## spatial and date info for data 1 and data 2
st <- df23 %>% as.data.frame() ## Summary of all Locations and dates of observations with the Keys (YEID) linking to the observations in SBToML and HLToMl data files


head(sb)
head(hh)
head(st, 3)


### clean data -----------------------------------------------------------------
### fix - ID should be int
sb$EventID <- round(sb$EventID) 
hh$EventID <- round(hh$EventID)
# unique(st$EventID)
st$EventID <- round(st$EventID)
st$OEID    <- round(st$OEID)



### fix - name
names(dfsummary) <- gsub(pattern = '%', replacement = '', x = names(dfsummary), ignore.case = T); names(dfsummary)
names(sb)
names(st)
names(sb) <- gsub(pattern = '%', replacement = '', x = names(sb), ignore.case = T)
names(hh) <- gsub(pattern = '%', replacement = '', x = names(hh), ignore.case = T)
names(st) <- gsub(pattern = '%', replacement = '', x = names(st), ignore.case = T)
names(st) <- gsub(pattern = 'Depth', replacement = 'Depth_dem', x = names(st), ignore.case = T) ### This depth at each location was determined using digital elevation data obtained from NOAA. 



### fix - YEID should be string
sb$YEID <- as.character(sb$YEID)
hh$YEID <- as.character(hh$YEID)
st$YEID <- as.character(st$YEID)

st1 <- st
```




## Read data NEW
```{r}
getwd()
list.files(path = './data_raw', pattern = '.xlsx$', full.names = T)

xlsx_new <- list.files(path = './data_raw', pattern = '^newData.xlsx', full.names = T); xlsx_new
excel_sheets(xlsx_new)


df31 <- read_excel(path = xlsx_new, sheet = 1, col_names = T) %>% # SBToML
  rename(Year = year,
         Depth = depth,
         Salin = Sal) %>%
  # rename_with(str_to_title) %>%
  dplyr::mutate(EventID = round(EventID),
                YEID = paste0(Year, '.', str_pad(string = EventID, width = 3, pad = "0"))) %>%
  dplyr::select(names(sb))


df32 <- read_excel(path = xlsx_new, sheet = 2, col_names = T) %>% # HLToML
  rename(Year = year,
         Depth = depth,
         Salin = Sal) %>%
  # rename_with(str_to_title) %>%
  dplyr::mutate(EventID = round(EventID),
                YEID = paste0(Year, '.', str_pad(string = EventID, width = 3, pad = "0"))) %>%
  dplyr::select(names(sb))


df33 <- read_excel(path = xlsx_new, sheet = 3, col_names = T) # StaToML
names(df33) <- names(st)


str(df31)


### read in the NEW summary data
dfsummary_new <- read_excel(path = "./data_raw/Summary_updated.xlsx", sheet = 1, col_names = T) %>%
  dplyr::filter(Year <= 2017)
```



## Combine data and save
```{r}
### combine old and new data
dt_sb <- rbind(sb, df31) %>% dplyr::mutate(Instrument = 'sb')
dt_hh <- rbind(hh, df32) %>% dplyr::mutate(Instrument = 'hh')
dt    <- rbind(dt_sb, dt_hh)
st    <- rbind(st1, df33)


### Save as R data ------------------------------------------------------------
save(dfsummary,  file = paste0(dir.output, "Summary.RData"))
save(dt, st, file = paste0(dir.output, "RawData.RData"))
```





# Data cleaning 
## Clean and format
```{r}
### To load the data again  ---------------------------------------------------
getwd()
load(paste0(dir.output, "Summary.RData"))
load(paste0(dir.output, "RawData.RData"))



### do data -------------------------------------------------------------------
names(dt)



### spatial info data ---------------------------------------------------------
###   convert UTM 15 N to lat/lon
sp <- st %>%
  drop_na() %>%
  mutate(E1000 = E*1000, N1000 = N*1000)

library(proj4)
proj4string <- "+proj=utm +zone=15 +north +ellps=WGS84 +datum=WGS84 +units=m +no_defs "

## lat and lon data
xy <- data.frame(x=sp$E1000, y=sp$N1000)

## Transformed data
pj <- project(xy = xy, proj = proj4string, inverse = T, degrees = T)
sp <- data.frame(sp, lat = pj$y, lon = pj$x) 
head(sp)

## change levels of the data sources
unique(sp$Source)
mylevel <- c("LUMCON", "TAMU", "UMCES", "SEAMAP", "EPA", "NECOP", "LDWF", "latx")
sp$Source <- factor(sp$Source, levels = mylevel)
levels(sp$Source)
## reverse the levels
sp$Source <- fct_rev(sp$Source)

## remove user-created columns
head(sp)
str(sp)
sp <- sp %>% dplyr::select(-c("E1000", "N1000")) 




### check the data ID ----------------------------------------------------------------------------
names(dt)
names(sp)

str(dt)
str(sp)

sp$YEID[duplicated(sp$YEID)]  ## no duplicated rows
length(unique(sp$YEID))       ## no duplicated rows, confirm the YEID is unique

print(paste0('There are ', length(unique(dt$YEID)), ' unique YEID in `dt`.'))
print(paste0('There are ', length(unique(sp$YEID)), ' unique YEID in `sp`.'))


### Are these two YEID the same?
ids.dt <- unique(dt$YEID); length(ids.dt) ## 9065
ids.sp <- unique(sp$YEID); length(ids.sp) ## 8117 ## less spatial info??????????????????????????????????????????????
ids.both <- intersect(ids.dt, ids.sp); length(ids.both)
ids.none <- setdiff(ids.dt, ids.sp);   length(ids.none)
ids.none.df <- data.frame(id = ids.none) %>% arrange(id)


### To check YEID in each dataframe
sp_check <- sp %>%           
  dplyr::mutate(
    EventID = as.integer(EventID),
    checkID     = EventID - OEID,
    YEID2       = paste0(Year, '.', str_pad(string = EventID, width = 3, pad = "0"))
    ) %>%
  arrange(YEID2, YEID) %>%
  dplyr::select(YEID, YEID2, Year, OEID, EventID, checkID) %>%
  dplyr::filter(checkID != 0)

# unique(sp_check$check)
## ??? OEID VS. EventID ???
## --> Response from Rohith Reddy Matli: OEID is the index Id. I had to reorder some of them due to addition of data from other programs. It was a bit confusing initially, but I have improved it over time. 
## so, basically, OEID (updated EventID) is the new index, acting as the same role of EventID in the two data. 




### is it possible to use spatial information from `dfsummary` 
###   to fill the missing info in sp? --> NO
length(unique(sp$YEID))
length(unique(dfsummary$YEID))
summary(dfsummary)
unique(dfsummary$Source)
dfsummary %>% dplyr::filter(is.na(Date))

sp_summ <- dfsummary %>%
  dplyr::filter(!YEID %in% unique(sp$YEID))





### check if the length of YEID in `dt` is the same as that of `sp` -------------------------------
###   e.g., 2000.03 in sb, while 2000.030 in sp
dt.test <- dt %>%
  dplyr::mutate(id_len = nchar(YEID)) %>%
  dplyr::filter(id_len !=8) %>%
  distinct(YEID, Year, .keep_all = T) %>%
  dplyr::mutate(YEID2 = paste0(Year, '_', str_pad(string = EventID, width = 3, pad = "0")))

sp.test <- sp %>%
  dplyr::mutate(id_len = nchar(YEID)) %>%
  dplyr::filter(id_len !=8) %>%
  distinct(YEID, Year, .keep_all = T)

unique(dt.test$id_len)
unique(sp.test$id_len)



### update the format of YEID ----------------------------------------------------------------------
###   '2000.01' can be '2000.010', which is not consistant!
dt <- dt %>%
  dplyr::mutate(YEID = paste0(Year, '_', str_pad(string = EventID, width = 3, pad = "0")))

sp <- sp %>%
  dplyr::mutate(#YEID_old = YEID,
                YEID = paste0(Year, '_', str_pad(string = OEID, width = 3, pad = "0")))


### check again
sp.test2 <- sp %>%
  dplyr::mutate(YEID1 = paste0(Year, '.', str_pad(string = EventID, width = 3, pad = "0")))
sp_check2 <- sp.test2 %>%
  dplyr::filter(YEID != YEID1)
sp <- sp %>% dplyr::select(-EventID)




### merge data and spatial info --------------------------------------------------------------------
dt.sp <- merge(x = dt, y = sp, by = 'YEID', all.x = T) %>%
  arrange(!is.na(DO), !is.na(lat))
head(dt.sp, 3)
```




## Check merged data
```{r}
### check merged data ==============================================================================

#### 1. for DO   -----------------------------------------------
dt.sp.na  <- dt.sp %>% filter(is.na(DO))   ## 10 NA 
##--- after checking back to the xlsx, these rows with NA should be 0
dt.sp <- dt.sp %>%
  # mutate(DO = replace(DO, is.na(DO), 0))
 dplyr::mutate(DO = if_else(is.na(DO), 0, DO))


#### 2. check `Source` in SBToML and HLToML -----------------------------
dt.sp.na_source  <- dt.sp %>% dplyr::filter(is.na(Source))   ## 5w+ NA ???????????????????????????????????????????????????????????????????????????????????????????????????????
### % of the samples do NOT have `Source` info?
percent(nrow(dt.sp.na_source)/nrow(dt.sp)) 
## which YEID?
unique(dt.sp.na_source$YEID)[1:10]

### save the YEIP that without `Source` info to xlsx --------------------
dt.sp.na_source_unique_YEID <- dt.sp.na_source %>%
  distinct(YEID, .keep_all = T) 

writexl::write_xlsx(x = dt.sp.na_source_unique_YEID, path = './__YEID without Source and location info.xlsx')



### which years have the most missing data?
dt.sp.na_source_unique_YEID %>%
  group_by(Year.x) %>%
  filter(Year.x > 2000) %>%
  tally()



sp %>%
  dplyr::filter(YEID == '1992_001')


## to check if any difference between these two columns?
dt.sp.yr  <- dt.sp %>% dplyr::filter_(~Year.x    != Year.y)  ## none
# dt.sp.ev1 <- dt.sp %>% filter_(~EventID.x != EventID.y)
# dt.sp.ev2 <- dt.sp %>% filter_(~EventID.x != OEID)         ## good - none
dt.sp.ev  <- dt.sp %>% dplyr::filter_(~EventID   != OEID)    ## good - none
# sp.ev     <- sp    %>% dplyr::filter_(~EventID   != OEID)    ## re-indexed EventID to OEID
# dt.sp.dep <- dt.sp %>% dplyr::filter_(~Depth     != Depth_dem) ## many are different (> 735810)




### update the data frame ====================================================================
dt.sp.update <- dt.sp %>% 
  dplyr::select(-grep('.y', names(.), ignore.case = T)) %>%      ## remove such cols
  rename_at(vars(contains('.x')), funs(sub('.x', '', .)))        ## rename such cols


names(dt.sp.update)

```




## Save cleaned data
```{r}
### bind two data together ------------------------------------------------------
df <- dt.sp.update %>%
  arrange(Year, YEID, Source) %>%
  dplyr::select(-EventID, -OEID) %>%
  dplyr::select(YEID, Year, Date, DO, Depth, Depth_dem, everything())

names(df)


df.na.source <- df %>% filter(is.na(Source))     ## many ????????????????????????????????????????????????
df.na.DO     <- df %>% filter(is.na(DO))         ## none


### save to csv ---------------------------------------------------------------
today <- format(Sys.time(), "%Y%m%d"); print(today)
fname_rdt <- paste0(dir.output, 'DO_Integrated_Matli_NCSU_cleaned.RData'); fname_rdt
fname_csv <- paste0(dir.output, 'DO_Integrated_Matli_NCSU_cleaned.csv');   fname_csv
save(df, sp, dfsummary, file = fname_rdt)
write.csv(df, file = fname_csv, row.names = F)

```




```{r reproduce the summary data}
dfsumm_li <- df %>%
  dplyr::filter(Depth>=3, 
                Depth <=80,
                !is.na(Source),
                !is.na(Date)) %>%
  ungroup() %>%
  group_by(YEID) %>%
  slice(which.max(Depth))

### --> looks similar results
```

