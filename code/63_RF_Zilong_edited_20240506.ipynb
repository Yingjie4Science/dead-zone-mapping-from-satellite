{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g:\\Shared drives\\gdrive\\_paper\\_phd_dissertation\\ch4_dead_zone\\Dead_Zone_telecoupling\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy import *\n",
    "from sklearn.ensemble  import  RandomForestRegressor\n",
    "from sklearn.model_selection  import  train_test_split\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import os\n",
    "import sys\n",
    "\n",
    "## need to change working directory when using Spyder \n",
    "path_current = os.getcwd()\n",
    "path_root    = os.path.dirname(path_current)\n",
    "print(path_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lag: 0\n",
      "R-squared scores: 0.5729\n",
      "lag: 1\n",
      "R-squared scores: 0.5778\n",
      "lag: 2\n",
      "R-squared scores: 0.585\n",
      "lag: 3\n",
      "R-squared scores: 0.5866\n",
      "lag: 4\n",
      "R-squared scores: 0.5898\n",
      "lag: 5\n",
      "R-squared scores: 0.5907\n",
      "lag: 6\n",
      "R-squared scores: 0.5895\n",
      "lag: 7\n",
      "R-squared scores: 0.5919\n",
      "lag: 8\n",
      "R-squared scores: 0.5882\n",
      "lag: 9\n",
      "R-squared scores: 0.5865\n",
      "lag: 10\n",
      "R-squared scores: 0.5872\n",
      "lag: 11\n",
      "R-squared scores: 0.5885\n",
      "lag: 12\n",
      "R-squared scores: 0.5875\n",
      "lag: 13\n",
      "R-squared scores: 0.585\n",
      "lag: 14\n",
      "R-squared scores: 0.5832\n",
      "lag: 15\n",
      "R-squared scores: 0.5842\n",
      "lag: 16\n",
      "R-squared scores: 0.583\n",
      "lag: 17\n",
      "R-squared scores: 0.5825\n",
      "lag: 18\n",
      "R-squared scores: 0.5818\n",
      "lag: 19\n",
      "R-squared scores: 0.5826\n",
      "lag: 20\n",
      "R-squared scores: 0.5809\n",
      "lag: 21\n",
      "R-squared scores: 0.5789\n",
      "lag: 22\n",
      "R-squared scores: 0.5794\n",
      "lag: 23\n",
      "R-squared scores: 0.5813\n",
      "lag: 24\n",
      "R-squared scores: 0.5818\n",
      "lag: 25\n",
      "R-squared scores: 0.5826\n",
      "lag: 26\n",
      "R-squared scores: 0.5844\n",
      "lag: 27\n",
      "R-squared scores: 0.584\n",
      "lag: 28\n",
      "R-squared scores: 0.5837\n",
      "lag: 29\n",
      "R-squared scores: 0.5821\n",
      "lag: 30\n",
      "R-squared scores: 0.5819\n",
      "lag: 31\n",
      "R-squared scores: 0.5822\n",
      "lag: 32\n",
      "R-squared scores: 0.583\n",
      "lag: 33\n",
      "R-squared scores: 0.5829\n",
      "lag: 34\n",
      "R-squared scores: 0.5814\n",
      "lag: 35\n",
      "R-squared scores: 0.5807\n",
      "lag: 36\n",
      "R-squared scores: 0.5801\n",
      "lag: 37\n",
      "R-squared scores: 0.5793\n",
      "lag: 38\n",
      "R-squared scores: 0.5784\n",
      "lag: 39\n",
      "R-squared scores: 0.5783\n",
      "lag: 40\n",
      "R-squared scores: 0.5778\n",
      "lag: 41\n",
      "R-squared scores: 0.5778\n",
      "lag: 42\n",
      "R-squared scores: 0.5777\n",
      "lag: 43\n",
      "R-squared scores: 0.5772\n",
      "lag: 44\n",
      "R-squared scores: 0.5766\n",
      "lag: 45\n",
      "R-squared scores: 0.5765\n",
      "lag: 46\n",
      "R-squared scores: 0.5769\n",
      "lag: 47\n",
      "R-squared scores: 0.577\n",
      "lag: 48\n",
      "R-squared scores: 0.5764\n",
      "lag: 49\n",
      "R-squared scores: 0.576\n",
      "lag: 50\n",
      "R-squared scores: 0.5762\n",
      "lag: 51\n",
      "R-squared scores: 0.5759\n",
      "lag: 52\n",
      "R-squared scores: 0.5756\n",
      "lag: 53\n",
      "R-squared scores: 0.5757\n",
      "lag: 54\n",
      "R-squared scores: 0.5757\n",
      "lag: 55\n",
      "R-squared scores: 0.5762\n",
      "lag: 56\n",
      "R-squared scores: 0.5763\n",
      "lag: 57\n",
      "R-squared scores: 0.576\n",
      "lag: 58\n",
      "R-squared scores: 0.5756\n",
      "lag: 59\n",
      "R-squared scores: 0.5739\n",
      "lag: 60\n",
      "R-squared scores: 0.5727\n",
      "lag: 61\n",
      "R-squared scores: 0.5721\n",
      "lag: 62\n",
      "R-squared scores: 0.5719\n",
      "lag: 63\n",
      "R-squared scores: 0.571\n",
      "lag: 64\n",
      "R-squared scores: 0.5704\n",
      "lag: 65\n",
      "R-squared scores: 0.5698\n",
      "lag: 66\n",
      "R-squared scores: 0.5703\n",
      "lag: 67\n",
      "R-squared scores: 0.5705\n",
      "lag: 68\n",
      "R-squared scores: 0.5705\n",
      "lag: 69\n",
      "R-squared scores: 0.5711\n",
      "lag: 70\n",
      "R-squared scores: 0.5714\n",
      "lag: 71\n",
      "R-squared scores: 0.5713\n",
      "lag: 72\n",
      "R-squared scores: 0.5711\n",
      "lag: 73\n",
      "R-squared scores: 0.5713\n",
      "lag: 74\n",
      "R-squared scores: 0.5722\n",
      "lag: 75\n",
      "R-squared scores: 0.5728\n",
      "lag: 76\n",
      "R-squared scores: 0.5729\n",
      "lag: 77\n",
      "R-squared scores: 0.5728\n",
      "lag: 78\n",
      "R-squared scores: 0.5727\n",
      "lag: 79\n",
      "R-squared scores: 0.5721\n",
      "lag: 80\n",
      "R-squared scores: 0.5719\n"
     ]
    }
   ],
   "source": [
    "index_list = ['Depth','water_temp_surface','water_temp_dif',\n",
    "              'chlor_a','nflh','Rrs_678',\n",
    "              'poc', 'sst', 'Rrs_667', 'Rrs_645',            ## not included by Zilong\n",
    "              'Rrs_443', 'Rrs_412', 'Rrs_469', 'Rrs_488',    ## not included by Zilong\n",
    "              'Rrs_555', 'Rrs_547', 'Rrs_531',               ## not included by Zilong, lowerest importance\n",
    "              'wind_speed',         # not included\n",
    "              'doy_img', \n",
    "              'nday_before',        # not included\n",
    "              'velocityu_surface',  # not included\n",
    "              'velocityu_dif', \n",
    "              'salinity_surface',\n",
    "              'salinity_dif',\n",
    "              'lon','lat']\n",
    "\n",
    "\n",
    "# path_data = 'D:\\\\D\\\\' ## Zilong\n",
    "path_data = path_root + '\\\\data\\\\from_gee\\\\rs_do_sample\\\\rs_do_sample_lagByDay\\\\'\n",
    "\n",
    "\n",
    "## to fit the model by year, or use all data as a whole\n",
    "# by_year  = 'yes'\n",
    "by_year  = 'no'\n",
    "\n",
    "\n",
    "## create empty list in order to collect results from each run\n",
    "lag_list = [];\n",
    "yr_list  = [];\n",
    "\n",
    "random_i = []\n",
    "mae_list = []\n",
    "mse_list = []\n",
    "r2_list = []\n",
    "\n",
    "zong_r2_list  = []\n",
    "zong_mae_list = []\n",
    "zong_mse_list = []\n",
    "\n",
    " \n",
    "importance_df = pd.DataFrame()\n",
    "for lag in range(0,81): # (0, 81) for initial test; (31,32) for the best lag\n",
    "        print('lag: ' + str(lag))\n",
    "        samples = pd.read_excel(path_data + 'RS_do_bottom_sample_2000_2019_byday_' + str(lag) + 'dayBefore.xlsx');\n",
    "\n",
    "        for ite in index_list:  \n",
    "            # 删除空值\n",
    "            samples = samples[samples[ite].notna()]\n",
    "        obj_num = []\n",
    "        \n",
    "        for yy in range(2003,2004): ## if by_year  = 'no', this line won't be used. \n",
    "            \n",
    "            if by_year == 'yes':\n",
    "                yr = yy\n",
    "            else:\n",
    "                yr = 1\n",
    "  \n",
    "            ## data test finds that only using data from 'SEAMAP' can achieve better accuracy\n",
    "            # samples2 = samples[samples['Source'] == 'SEAMAP'];\n",
    "            samples2 = samples;\n",
    "            \n",
    "            X = samples2[index_list]\n",
    "            Y = samples2[['DO']]\n",
    "            # mae_list = []\n",
    "            # mse_list = []\n",
    "            # r2_list = []\n",
    "            for i in range(20):   #循环20次验证精度\n",
    "                X_train ,  X_test ,  y_train ,  y_test  =  train_test_split( X , Y ,  test_size  = 0.3)\n",
    "                regr = RandomForestRegressor() #参数默认\n",
    "                regr.fit(X_train, y_train.values.ravel())\n",
    "                warnings.filterwarnings('ignore')\n",
    "                predictions = regr.predict(X_test)\n",
    "                result = X_test\n",
    "                result['price'] = y_test\n",
    "                result['prediction'] = predictions.tolist()\n",
    "                ## save the result\n",
    "                if lag in [31, 32]:\n",
    "                    file_name = path_root + '\\\\data\\\\results_RF\\\\rf_prediction_lag_' + str(lag) + 'loop' + str(i) + '.csv'\n",
    "                    result.to_csv(file_name, index=False)\n",
    "                \n",
    "                mae = mean_absolute_error(y_test.values.ravel(), predictions)\n",
    "                mse = mean_squared_error(y_test.values.ravel(), predictions)\n",
    "                r2 = r2_score(y_test.values.ravel(), predictions)\n",
    "                # print(r2)\n",
    "                mse_list.append(mse)\n",
    "                mae_list.append(mae)\n",
    "                r2_list.append(r2)\n",
    "                lag_list.append(lag)\n",
    "                yr_list.append(yr)\n",
    "                random_i.append(i)\n",
    "                \n",
    "                ## to get the variable importance score\n",
    "                import_list = []\n",
    "                score_list  = []\n",
    "                \n",
    "                characteristics = X.columns\n",
    "                importances = list(regr.feature_importances_)\n",
    "                characteristics_importances = [(characteristic, round(importance, 2)) for characteristic, importance in zip(characteristics, importances)]\n",
    "                characteristics_importances = sorted(characteristics_importances, key = lambda x: x[1], reverse = True)\n",
    "                for pair in characteristics_importances:\n",
    "                    import_list.append(pair[0])\n",
    "                    score_list.append(pair[1])\n",
    "                # [print('Variable: {:20} Importance: {}'.format(*pair)) for pair in characteristics_importances]; #打印变量重要性\n",
    "                imp_dict = {'year': yr,\n",
    "                            'lag': lag,\n",
    "                            'random_i': i,\n",
    "                            'var': import_list,\n",
    "                            'score': score_list}\n",
    "                imp_df = pd.DataFrame(imp_dict)\n",
    "\n",
    "                ##  Starting with pandas version 1.4.0, \n",
    "                ##  the append method is deprecated and will be removed in a future release. \n",
    "                ##  Instead, you should use the concat() function to combine DataFrames\n",
    "                # importance_df = importance_df.append(imp_df, ignore_index=True) \n",
    "                importance_df = pd.concat([importance_df, imp_df], ignore_index=True)\n",
    "\n",
    "\n",
    "            ## calculate the mean of 20 models\n",
    "            # print('Mean Absolute Error:',round(mean(mae_list),2))\n",
    "            # print('Mean Squared Error:',round(mean(mse_list),2))\n",
    "            print('R-squared scores:',round(mean(r2_list),4))\n",
    "            # zong_r2_list.append(round(mean(r2_list),4))\n",
    "            # zong_mae_list.append(round(mean(mae_list), 4))\n",
    "            # zong_mse_list.append(round(mean(mse_list), 4))\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g:\\Shared drives\\gdrive\\_paper\\_phd_dissertation\\ch4_dead_zone\\Dead_Zone_telecoupling\\data\\results_RF\\rf_r2_mse_mae_by_yearNO_26vars.csv\n",
      "g:\\Shared drives\\gdrive\\_paper\\_phd_dissertation\\ch4_dead_zone\\Dead_Zone_telecoupling\\data\\results_RF\\rf_importance_by_yearNO_26vars.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(zong_r2_list)\n",
    "# print(zong_mae_list)\n",
    "# print(zong_mse_list)\n",
    "\n",
    "# print(r2_list)\n",
    "# print(lag_list)\n",
    "# print(score_list)\n",
    "# print(characteristics_importances)\n",
    "\n",
    "# put the raw data into a dictionary of lists, and then convert it to a dataframe, then csv\n",
    "dict = {'year': yr_list,\n",
    "        'lag': lag_list,\n",
    "        'random_i': random_i,\n",
    "        'r2':  r2_list,\n",
    "        'mae': mae_list,\n",
    "        'mse': mse_list}\n",
    "# creating a dataframe from list\n",
    "df = pd.DataFrame(dict)\n",
    "\n",
    "file_name = path_root + '\\\\data\\\\results_RF\\\\rf_r2_mse_mae_' + 'by_year' + by_year.upper() + '_' + str(len(index_list)) + 'vars.csv'; print(file_name)\n",
    "df.to_csv(file_name, index=False)\n",
    "\n",
    "file_name = path_root + '\\\\data\\\\results_RF\\\\rf_importance_' + 'by_year' + by_year.upper() + '_' + str(len(index_list)) + 'vars.csv'; print(file_name)\n",
    "importance_df.to_csv(file_name, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
